{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c5727da",
   "metadata": {},
   "source": [
    "# In this notebook the MLABite results are injected in the DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6957ff4a",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Ingest \"global_evaluation\" CSV into the existing BESSER-generated SQLite DB.\n",
    "\n",
    "What it does (high level):\n",
    "- Opens DB and introspects table columns with PRAGMA.\n",
    "- Ensures a Project, Tool, Evaluation, Datashape exist.\n",
    "- Creates one Dataset per CSV slice (by language if 'language' column exists; else a single 'global' dataset).\n",
    "- Creates one Observation per slice.\n",
    "- For every numeric CSV column (except ignore list), ensures a Metric exists and inserts a Measure linked to the Observation.\n",
    "- Writes values, plus optional unit, uncertainty, error if present/desired.\n",
    "\n",
    "Customize the CONFIG section as needed.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281b679",
   "metadata": {},
   "source": [
    "## Load libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b7aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0a4d877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-30 12:45:43+0000\n"
     ]
    }
   ],
   "source": [
    "from datetime import timezone\n",
    "\n",
    "when_now = datetime.now(timezone.utc).strftime(\"%Y-%m-%d %H:%M:%S%z\")\n",
    "print(when_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22d9172",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd7ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH   = r\"ai_sandbox_PSA_16_Oct_2025_MLABite.db\"\n",
    "CSV_PATH  = r\"MLABiTe/20250704_160557/en_us/OpenAIGPT35Turbo/20250704160636_global_evaluation.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8babd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlabite = pd.read_csv(CSV_PATH, sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ea42e",
   "metadata": {},
   "source": [
    "## Some delcarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2cd748a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME   = \"ai-sandbox\"\n",
    "PROJECT_STATUS = \"Processing\"\n",
    "\n",
    "TOOL_NAME    = \"GlobalEval Loader\"\n",
    "TOOL_SOURCE  = \"CSV Import\"\n",
    "TOOL_VERSION = \"1.0\"\n",
    "TOOL_LICENSE = \"Open-source\"\n",
    "\n",
    "CONFIG_NAME        = \"GlobalEval Config\"\n",
    "CONFIG_DESCRIPTION = \"Config for global evaluation import\"\n",
    "\n",
    "EVAL_STATUS   = \"Processing\"\n",
    "DATASET_TYPE  = \"Validation\"      # adjust to your enum\n",
    "DATASET_SRC   = \"Global Evaluation CSV\"\n",
    "DATASET_VER   = \"v1\"\n",
    "DATASET_LIC   = \"Open-source\"     # adjust to your enum\n",
    "\n",
    "DEFAULT_UNIT = \"\"\n",
    "NON_METRIC_COLUMNS = {\"language\", \"split\", \"subset\", \"run_id\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebbe130",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b823e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_cols(conn, table):\n",
    "    try:\n",
    "        return {r[1] for r in conn.execute(f\"PRAGMA table_info('{table}');\").fetchall()}\n",
    "    except sqlite3.OperationalError:\n",
    "        return set()\n",
    "\n",
    "def one(conn, q, params=()):\n",
    "    cur = conn.execute(q, params); row = cur.fetchone(); cur.close()\n",
    "    return row[0] if row else None\n",
    "\n",
    "def exists_table(conn, name):\n",
    "    return one(conn, \"SELECT 1 FROM sqlite_master WHERE type='table' AND name=?\", (name,)) is not None\n",
    "\n",
    "def insert_dynamic(conn, table, data):\n",
    "    cols = table_cols(conn, table)\n",
    "    payload = {k: v for k, v in data.items() if k in cols}\n",
    "    keys = \", \".join(payload.keys())\n",
    "    qms  = \", \".join([\"?\"]*len(payload))\n",
    "    if not keys:\n",
    "        raise RuntimeError(f\"No matching columns to insert into {table}\")\n",
    "    cur = conn.execute(f\"INSERT INTO {table} ({keys}) VALUES ({qms})\", tuple(payload.values()))\n",
    "    return cur.lastrowid\n",
    "\n",
    "def update_dynamic(conn, table, pk_field, pk_value, updates):\n",
    "    cols = table_cols(conn, table)\n",
    "    payload = {k: v for k, v in updates.items() if k in cols}\n",
    "    if not payload:\n",
    "        return\n",
    "    sets = \", \".join([f\"{k}=?\" for k in payload.keys()])\n",
    "    conn.execute(f\"UPDATE {table} SET {sets} WHERE {pk_field}=?\", (*payload.values(), pk_value))\n",
    "\n",
    "# If you have joined inheritance and NOT NULL element.project_id:\n",
    "def ensure_element(conn, type_spec, name, description, project_id):\n",
    "    if not exists_table(conn, \"element\"):\n",
    "        return None\n",
    "    eid = one(conn, \"SELECT id FROM element WHERE type_spec=? AND name=? AND project_id=?\",\n",
    "              (type_spec, name, project_id))\n",
    "    if eid:\n",
    "        update_dynamic(conn, \"element\", \"id\", eid, {\"description\": description})\n",
    "        return eid\n",
    "    return insert_dynamic(conn, \"element\", {\n",
    "        \"type_spec\": type_spec, \"name\": name, \"description\": description, \"project_id\": project_id\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d6eb67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Upserts (with required FKs) ---\n",
    "def ensure_project(conn, name, status):\n",
    "    if not exists_table(conn, \"project\"):\n",
    "        raise RuntimeError(\"Table 'project' not found.\")\n",
    "    pid = one(conn, \"SELECT id FROM project WHERE name=?\", (name,))\n",
    "    if pid:\n",
    "        update_dynamic(conn, \"project\", \"id\", pid, {\"status\": status})\n",
    "        return pid\n",
    "    return insert_dynamic(conn, \"project\", {\"name\": name, \"status\": status})\n",
    "\n",
    "def ensure_configuration(conn, name, description):\n",
    "    if not exists_table(conn, \"configuration\"):\n",
    "        raise RuntimeError(\"Table 'configuration' not found.\")\n",
    "    cid = one(conn, \"SELECT id FROM configuration WHERE name=?\", (name,))\n",
    "    if cid:\n",
    "        update_dynamic(conn, \"configuration\", \"id\", cid, {\"description\": description})\n",
    "        return cid\n",
    "    return insert_dynamic(conn, \"configuration\", {\"name\": name, \"description\": description})\n",
    "\n",
    "def ensure_tool(conn, name, source, version, licensing, project_id):\n",
    "    if not exists_table(conn, \"tool\"):\n",
    "        return None\n",
    "    tid = one(conn, \"SELECT id FROM tool WHERE name=? AND version=?\", (name, version))\n",
    "    if tid:\n",
    "        update_dynamic(conn, \"tool\", \"id\", tid, {\"source\": source, \"licensing\": licensing})\n",
    "        return tid\n",
    "    base_id = ensure_element(conn, \"Tool\", name, \"\", project_id)\n",
    "    return insert_dynamic(conn, \"tool\", {\n",
    "        \"id\": base_id, \"name\": name, \"source\": source, \"version\": version, \"licensing\": licensing\n",
    "    })\n",
    "\n",
    "def ensure_evaluation(conn, status, project_id, config_id):\n",
    "    # IMPORTANT: this table requires project_id & config_id (NOT NULL)\n",
    "    if not exists_table(conn, \"evaluation\"):\n",
    "        return None\n",
    "    eid = one(conn, \"SELECT id FROM evaluation WHERE project_id=? AND config_id=? LIMIT 1\",\n",
    "              (project_id, config_id))\n",
    "    if eid:\n",
    "        update_dynamic(conn, \"evaluation\", \"id\", eid, {\"status\": status})\n",
    "        return eid\n",
    "    return insert_dynamic(conn, \"evaluation\", {\n",
    "        \"status\": status, \"project_id\": project_id, \"config_id\": config_id\n",
    "    })\n",
    "\n",
    "def ensure_datashape(conn, accepted_target_values, project_id):\n",
    "    if not exists_table(conn, \"datashape\"):\n",
    "        return None\n",
    "    atv_json = json.dumps(accepted_target_values, ensure_ascii=False)\n",
    "    did = one(conn, \"SELECT id FROM datashape WHERE accepted_target_values=?\", (atv_json,))\n",
    "    if did:\n",
    "        return did\n",
    "    base_id = ensure_element(conn, \"Datashape\", \"global_eval_shape\", \"Accepted structure for global eval\", project_id)\n",
    "    return insert_dynamic(conn, \"datashape\", {\"id\": base_id, \"accepted_target_values\": atv_json})\n",
    "\n",
    "def ensure_dataset(conn, name, datashape_id, project_id, source, version, licensing, dtype):\n",
    "    if not exists_table(conn, \"dataset\"):\n",
    "        return None\n",
    "    dsid = one(conn, \"SELECT id FROM dataset WHERE source=? AND version=? AND type=? AND datashape_id=? LIMIT 1\",\n",
    "               (source, version, dtype, datashape_id))\n",
    "    if dsid:\n",
    "        return dsid\n",
    "    base_id = ensure_element(conn, \"Dataset\", name, \"\", project_id)\n",
    "    return insert_dynamic(conn, \"dataset\", {\n",
    "        \"id\": base_id, \"source\": source, \"version\": version,\n",
    "        \"licensing\": licensing, \"type\": dtype, \"datashape_id\": datashape_id\n",
    "    })\n",
    "\n",
    "def ensure_observation(conn, name, observer, whenObserved, tool_id, evaluation_id, dataset_id, project_id):\n",
    "    # REQUIRED columns in your DB: whenObserved, tool_id, eval_id, dataset_2_id (all NOT NULL)\n",
    "    if not exists_table(conn, \"observation\"):\n",
    "        return None\n",
    "    oid = one(conn, \"SELECT id FROM observation WHERE name=?\", (name,))\n",
    "    payload = {\n",
    "        \"observer\": observer,\n",
    "        \"whenObserved\": whenObserved,\n",
    "        \"tool_id\": tool_id,\n",
    "        \"eval_id\": evaluation_id,\n",
    "        \"dataset_2_id\": dataset_id\n",
    "    }\n",
    "    if oid:\n",
    "        update_dynamic(conn, \"observation\", \"id\", oid, payload)\n",
    "        return oid\n",
    "    base_id = ensure_element(conn, \"Observation\", name, \"\", project_id)\n",
    "    payload.update({\"id\": base_id, \"name\": name, \"description\": f\"Imported {name}\"})\n",
    "    return insert_dynamic(conn, \"observation\", payload)\n",
    "\n",
    "def ensure_metric(conn, metric_name, description, project_id):\n",
    "    if not exists_table(conn, \"metric\"):\n",
    "        return None\n",
    "    mid = one(conn, \"SELECT id FROM metric WHERE name=?\", (metric_name,))\n",
    "    if mid:\n",
    "        return mid\n",
    "    base_id = ensure_element(conn, \"Metric\", metric_name, description, project_id)\n",
    "    return insert_dynamic(conn, \"metric\", {\"id\": base_id, \"name\": metric_name, \"description\": description})\n",
    "\n",
    "def insert_measure(conn, metric_id, observation_id, measurand_id, value, unit=DEFAULT_UNIT, uncertainty=0.0, error=\"\"):\n",
    "    if not exists_table(conn, \"measure\"):\n",
    "        return None\n",
    "    return insert_dynamic(conn, \"measure\", {\n",
    "        \"metric_id\": metric_id,\n",
    "        \"observation_id\": observation_id,\n",
    "        \"measurand_id\": measurand_id,  # <- REQUIRED in your schema\n",
    "        \"value\": str(value),\n",
    "        \"unit\": unit,\n",
    "        \"uncertainty\": float(uncertainty),\n",
    "        \"error\": error\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3047ef",
   "metadata": {},
   "source": [
    "## Populate DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6fcbfcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 1) Load CSV\n",
    "    df = pd.read_csv(CSV_PATH, sep=';')\n",
    "\n",
    "    # 2) Group by slice (language) if present\n",
    "    if \"language\" in df.columns:\n",
    "        groups = df.groupby(\"language\")\n",
    "    else:\n",
    "        df[\"_slice\"] = \"global\"\n",
    "        groups = df.groupby(\"_slice\")\n",
    "\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    conn.execute(\"PRAGMA foreign_keys = ON;\")\n",
    "\n",
    "    with conn:\n",
    "        # 3) Required parents FIRST\n",
    "        project_id = ensure_project(conn, PROJECT_NAME, PROJECT_STATUS)\n",
    "        config_id  = ensure_configuration(conn, CONFIG_NAME, CONFIG_DESCRIPTION)\n",
    "        tool_id    = ensure_tool(conn, TOOL_NAME, TOOL_SOURCE, TOOL_VERSION, TOOL_LICENSE, project_id)\n",
    "        eval_id    = ensure_evaluation(conn, EVAL_STATUS, project_id, config_id)\n",
    "        datashape_id = ensure_datashape(conn, {\"schema\": \"wide_metrics\"}, project_id)\n",
    "\n",
    "        # 4) Per-slice dataset + observation, then measures\n",
    "        inserted = 0\n",
    "        for slice_key, sub in groups:\n",
    "            ds_name = f\"global_eval__{slice_key}\"\n",
    "            ds_id   = ensure_dataset(conn, ds_name, datashape_id, project_id,\n",
    "                                     DATASET_SRC, DATASET_VER, DATASET_LIC, DATASET_TYPE)\n",
    "\n",
    "            when_ts = when_now#datetime.datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            obs_name = f\"obs__{slice_key}__{Path(CSV_PATH).stem}\"\n",
    "            obs_id   = ensure_observation(conn, obs_name, TOOL_NAME, when_ts,\n",
    "                                          tool_id, eval_id, ds_id, project_id)\n",
    "\n",
    "            candidate_cols = [c for c in sub.columns if c not in NON_METRIC_COLUMNS]\n",
    "            num_df = sub[candidate_cols].select_dtypes(include=[\"number\"])\n",
    "            if num_df.empty:\n",
    "                continue\n",
    "\n",
    "            row = num_df.mean(numeric_only=True)   # aggregate to one measure per metric per slice\n",
    "            for col, val in row.items():\n",
    "                metric_name = col\n",
    "                mid = ensure_metric(conn, metric_name, f\"Imported from {Path(CSV_PATH).name}\", project_id)\n",
    "                insert_measure(conn, mid, obs_id, ds_id, float(val), unit=DEFAULT_UNIT)\n",
    "                inserted += 1\n",
    "\n",
    "        print(f\"Done. Slices: {len(list(groups))}, measures inserted: {inserted}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a961f95",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fec3a3f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "NOT NULL constraint failed: metric.type_spec",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[56], line 43\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, val \u001b[38;5;129;01min\u001b[39;00m row\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     42\u001b[0m     metric_name \u001b[38;5;241m=\u001b[39m col\n\u001b[1;32m---> 43\u001b[0m     mid \u001b[38;5;241m=\u001b[39m \u001b[43mensure_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mImported from \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCSV_PATH\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     insert_measure(conn, mid, obs_id, ds_id, \u001b[38;5;28mfloat\u001b[39m(val), unit\u001b[38;5;241m=\u001b[39mDEFAULT_UNIT)\n\u001b[0;32m     45\u001b[0m     inserted \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[55], line 94\u001b[0m, in \u001b[0;36mensure_metric\u001b[1;34m(conn, metric_name, description, project_id)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mid\n\u001b[0;32m     93\u001b[0m base_id \u001b[38;5;241m=\u001b[39m ensure_element(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetric\u001b[39m\u001b[38;5;124m\"\u001b[39m, metric_name, description, project_id)\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minsert_dynamic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetric\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdescription\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[54], line 21\u001b[0m, in \u001b[0;36minsert_dynamic\u001b[1;34m(conn, table, data)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m keys:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo matching columns to insert into \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m cur \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mINSERT INTO \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtable\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mkeys\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m) VALUES (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mqms\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cur\u001b[38;5;241m.\u001b[39mlastrowid\n",
      "\u001b[1;31mIntegrityError\u001b[0m: NOT NULL constraint failed: metric.type_spec"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
